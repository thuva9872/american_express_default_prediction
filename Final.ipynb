{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt, gc, os\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport os\nimport lightgbm\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\nimport numpy as np\nimport pandas as pd\nimport warnings\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, RocCurveDisplay, accuracy_score\nimport shap\nimport itertools","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_parquet(\"/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet\").groupby('customer_ID').tail(4)\ntest = pd.read_parquet(\"/kaggle/input/amex-data-integer-dtypes-parquet-format/test.parquet\").groupby('customer_ID').tail(4)\ntrain_labels = pd.read_csv(\"../input/amex-default-prediction/train_labels.csv\")\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shapes\ntrain.shape, test.shape, train_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking Missing values having more than 40%\ncolumns = train.columns[(train.isna().sum()/len(train))*100>40]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop the missing columns having more than 40%\ntrain = train.drop(columns, axis=1)\ntest = test.drop(columns, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fill the missing values\ntrain = train.bfill(axis='rows').ffill(axis='rows')\ntest = test.bfill(axis='rows').ffill(axis='rows')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.reset_index(inplace=True)\ntest.reset_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train =train.groupby('customer_ID').tail(1)\ntest = test.groupby('customer_ID').tail(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape\ntrain.shape, train_labels.shape, test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Type Conversion\nobj_col = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\nfor col in obj_col:\n    train[col]=train[col].astype('int').astype('str')\n    test[col]=test[col].astype('int').astype('str')\n    print(train[col].unique())\n    print(test[col].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preparation**","metadata":{}},{"cell_type":"code","source":"train = train.merge(train_labels, how='inner', on=\"customer_ID\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test.copy()\ntrain = train.drop(['index','customer_ID', 'S_2'], axis=1)\ntest = test.drop(['index','customer_ID', 'S_2'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one hot Encoding for categorical features\nobj_col = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\ntrain = pd.get_dummies(train, columns=obj_col, drop_first=True)\ntest = pd.get_dummies(test, columns=obj_col, drop_first=True)\ntrain.shape, test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Features=train.loc[:, test.columns]\ntarget = train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# Create an instance of the StandardScaler\nscaler = StandardScaler()\ncols=Features.columns\n# Fit the scaler to the DataFrame\nscaler.fit(Features)\n\n# Transform the DataFrame\nFeatures = scaler.transform(Features)\nFeatures=pd.DataFrame(Features, columns=cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into a training and test set\nX_train, X_test, y_train, y_test = train_test_split(Features, target, test_size=0.3, random_state=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Building and Evaluation**","metadata":{}},{"cell_type":"markdown","source":"   **1) SVM Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\n\n# Define the hyperparameters and their possible values\nparam_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'],'gamma':[0.1,1,10, 100]}\n\n# Create the SVM classifier\nsvm_clf = svm.SVC()\n\n# Perform a grid search to find the best hyperparameters\ngrid_search = GridSearchCV(svm_clf, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n# Get the best hyperparameters from the grid search\nbest_params = grid_search.best_params_\n\n# Create a new SVM classifier with the best hyperparameters\nbest_svm = svm.SVC(**best_params)\n\n# Fit the best model to the data\nbest_svm.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=best_svm.pred(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(13,5))\nplt.title(\"Confusion Matrix\")\nplt.imshow(cm, alpha=0.5, cmap='PuBu')\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment=\"center\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AUC (ROC curve)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(fpr, tpr)\ndisplay = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=XGB)\ndisplay.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) KNN Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Define the hyperparameters and their possible values\nparam_grid = {'n_neighbors': [3,5,7,9,11], 'weights': ['uniform', 'distance'],'metric':['minkowski','euclidean']}\n\n# Create the KNN classifier\nknn = KNeighborsClassifier()\n\n# Perform a grid search to find the best hyperparameters\ngrid_search = GridSearchCV(knn, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the best hyperparameters from the grid search\nbest_params = grid_search.best_params_\n\n# Create a new KNN classifier with the best hyperparameters\nbest_knn = KNeighborsClassifier(**best_params)\n\n# Fit the best model to the data\nbest_knn.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=best_knn.pred(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(13,5))\nplt.title(\"Confusion Matrix\")\nplt.imshow(cm, alpha=0.5, cmap='PuBu')\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment=\"center\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AUC (ROC curve)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(fpr, tpr)\ndisplay = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=XGB)\ndisplay.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) XGBClassifier**","metadata":{}},{"cell_type":"code","source":"XGB = XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1).fit(Features, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(cross_val_score(XGB, Features, target, scoring='accuracy', cv=5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = XGB.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(13,5))\nplt.title(\"Confusion Matrix\")\nplt.imshow(cm, alpha=0.5, cmap='PuBu')\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment=\"center\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AUC (ROC curve)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(fpr, tpr)\ndisplay = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=XGB)\ndisplay.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Submission to Kaggle**","metadata":{}},{"cell_type":"code","source":"test_data['prediction']=XGB.predict_proba(test)[:,1]\ntest_data[['customer_ID','prediction']].to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}